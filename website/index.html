
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Starter Template for Bootstrap</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Binny the Trashbot</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#drawings">Drawings</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="starter-template">
        <h1>Binny the Trashbot</h1>
        <p class="lead">A Pi Powered Trash Can That Makes Garbage Fun!<br>By Dyllan Hofflich (drh253) and Laurence Lai (ll758)</p>
        <img class="img-rounded" src="pics/binny.jpg" alt="Binny the Trashbot" width=90% height=90%>
      </div>

      <hr>
      <div class="center-block">
          <h4 style="text-align:center;">Demonstration Video</h4>
          <iframe width="640" height="360" src="https://www.youtube.com/embed?v=et91Gea6CPk" frameborder="0" allowfullscreen></iframe>
      </div>

      <hr id="intro">

      <div style="text-align:center;">
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;">Do you hate how tedious throwing trash away is and how boring it feels? We have the solution for you! Binny is an automated interactive trash can that encourages a greener world by following humans around and enticing them to throw away garbage with its quirky and demanding personality. Packed with a robust computer vision algorithm and fun interfaces like speakers for its voice, bright LED lights, clap sound detection, and a Wifi connected webpage, Binny is sure to make trash throwing exciting again!</p>
              <img class="img-rounded" src="pics/binny_angles.png" alt="Binny the Trashbot" width=90% height=90%>
              <p style="text-align: left;padding: 0px 30px;">Using a Raspberry Pi 4, Binny uses a USB webcam to run a YOLO object detection model to identify and track human objects nearby. Once detected, the Pi takes in the center xy coordinates of a detected person and commands directions to Binny's motorized wheel base to move towards a person. Ultrasonic senors are utilized for object avoidance behavior to prevent Binny from running into obstacles. A PiTFT screen is utilized to provide a real time monitor of Binny's object detection model as well as measured ultrasonic distances. Additionally, a sound sensor detects loud claps and triggers Binny to spin around and look for a person when idle. Bluetooth speaker connectivity is also provided to give life to Binny and provide him with a voice to interact with users and give updates on his tracking algorithm. Binny also hosts a webpage on its Wifi hotspot to toggle between manual and automated trash can control. Lastly, LEDs were included because they look cool and provide a sick startup animation!
              </p>
      </div>

    <hr id='obj'>

      <div class="row">
          <div class="col-md-8" style="font-size:18px;">
          <h2>Project Objectives</h2>
          <ul>
              <li>Develop a motorized base for a small trash can as well as a motor control interface.</li>
              <li>Use comptuer vision on the Pi to track and follow people based on xy coordinates.</li>
              <li>Uitlize ultrasoic sensors for obstacle avoidance behavior.</li>
              <li>Provide fun user interactivity features such as speakers, lights, and clap sound detection.</li>
              </ul>
          </div>
      </div>

    <hr id='drawings'>

      <div style="text-align:center;">
              <h2>Drawings</h2>
              <img class="img-round" src="pics/init_drawing.png" alt="Initial Propsosal" width=100%>
              <p style="text-align: left;padding: 0px 30px;">The image above showcases the first rudimentary mockup design of Binny. Trashbot was initally proposed to follow and catch trash thrown in the air in real time so it would always land in the bin. However, after initial software testing and disucssion with Dr. Ma and our TAs, the hardware limitations of the Pi make it extremely complex to have real time trajectory prediction and movement to catch flying trash in the air. Even after overclocking and lowering the complexity of our YOLO algorithm, the average FPS of our model stayed around 7. Note that in our initial drawings, we did not include additional features like ultrasonic sensors, lights, and clap sensors. These additions were formed throughout the development process in desire for a more interactive and fun project.</p>
      </div>
    
    <hr id='design'>

      <div style="text-align:center;">
            <h2>Design</h2>
              <h3>Mechanical Hardware</h3>
              <div style="display: flex; gap: 10px;">
                  <img class="img-round" src="pics/cad1.png" alt="Initial Proposal" style="width: 33%;">
                  <img class="img-round" src="pics/cad2.png" alt="Initial Proposal" style="width: 33%;">
                  <img class="img-round" src="pics/cad3.png" alt="Initial Proposal" style="width: 33%;">
              </div>
              <p style="text-align: left;padding: 0px 30px;">The images above show the Fusion 360 CAD mechanical model that we 3D printed for our project. Our goal for this design was to extend the bottom of an already existing trash can and neatly enclose all eletrical components. Notice that in our design, we kept motor mounts separate from the actual bin assembly to make printing easier and to allow for more rapid prototyping changes in case our motor mounts were incorrect (which happened many times). The extended bin base provides enough space to enclose a Pi 4, motor drivers, a long breadboard, and other tiny sensors such as the big sound sensor. A retangular hole is cut out in order to provide mounting for the PiTFT screen. The trash can is friction fit into the top of the extended base rim. A wide hole in the back provides open access to ports on the Pi and connections to battery chargers and the USB webcam mounted on top of the trashcan. Holes used in the design are made to fit M3 screws and nuts. Our final print was made out of PLA due to its low cost and faster printing time, as well as slightly more flexibility over more rigid materials like PETG.</p>
              
              <div style="display: flex; gap: 10px;">
                  <img class="img-round" src="pics/old_motor_mounts.png" alt="Initial Proposal" style="width: 30%;">
                  <img class="img-round" src="pics/new_motor_mounts.png" alt="Initial Proposal" style="width: 70%;">
              </div>

              <p style="text-align: left;padding: 0px 30px;"> One major mechanical issue we encountered in mechanical assembly were our motor mount designs. Initialy, our robot utilized larger RS550 12V DC motors but we eventually replaced our motors to use our Lab 3 DC gearbox motors. Since our motor mounts were a separate component from the extended bottom base, it was fairly simple to swap out these mounts. The images above showcase our motor swap, with the old RS550 design on the left and Lab 3 motor design on the right.</p>
              
              

              <h3>Electrical Hardware</h3>
              <img class="img-round" src="pics/circuit_image.png" alt="Initial Propsosal" width=100%>
              Binny contains a wide variety of electrical components, each with their own functionality. The breadboard diagram 

              <h3>Software</h3>
              <li>Computer Vision: (overclocking and overvoltage, shrinking model, detection scheme, camera)</li>
              <li>motor control</li>
              <li>ultrasonic sensing</li>
              <li>clap detection</li>
              <li>LEDs</li>
              <li>website and hotspot</li>
              <li>speaker voice</li>
              <li>PiTFT display</li>

              <h4>Computer Vision</h4>
              
              <p style="text-align: left;padding: 0px 30px;">
              To enable Binny to follow humans around, we implemented a computer vision algorithm using the YOLO (You Only Look Once) object detection model. 
              We chose YOLO for its speed and accuracy, 
              making it suitable for real-time applications on the Raspberry Pi, and because initially, we were aiming to detect a variety of objects as they flew in the air in real-time, however, this. We used a pre-trained YOLOv11n model. The model was optimized to run efficiently on the 
              Raspberry Pi by reducing its size and complexity, allowing Binny to process video frames at a reasonable frame rate. The camera captures video frames, which are then processed by the 
              YOLO model to detect humans. The model outputs bounding boxes around detected humans along with their confidence scores. We extract 
              the center coordinates of the bounding boxes 
              to determine the position of the person relative to Binny. These coordinates are then used to calculate the direction and speed at which 
              Binny should move to follow the detected person.
              </p>
              

            
              <!-- <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p> -->
      </div>

    <hr id='testing'>

      <div style="text-align:center;">
              <h2>Testing</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr id='result'>

      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Project group picture</h4>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/a.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Rick</h3>
              <p class="lead">netid@cornell.edu</p>
              <p>Designed the overall software architecture (Just being himself).
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/b.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Morty</h3>
              <p class="lead">netid@cornell.edu</p>
              <p>Tested the overall system.
          </div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi $35.00</li>
              <li>Raspberry Pi Camera V2 $25.00</li>
              <a href="https://www.adafruit.com/product/1463"><li>NeoPixel Ring - $9.95</li></a>
              <li>LEDs, Resistors and Wires - Provided in lab</li>
          </ul>
          <h3>Total: $69.95</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="http://www.micropik.com/PDF/SG90Servo.pdf">Tower Pro Servo Datasheet</a><br>
          <a href="http://getbootstrap.com/">Bootstrap</a><br>
          <a href="http://abyz.co.uk/rpi/pigpio/">Pigpio Library</a><br>
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a><br>

      </div>

    <hr>

      <div class="row">
              <h2>Code Appendix</h2>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>
      </div>

    </div><!-- /.container -->




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
